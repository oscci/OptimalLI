---
title: "Individual differences in language lateralisation: an exploratory study comparing functional transcranial Doppler ultrasound and fMRI"
bibliography: fliprefs.bib
format: html
editor: visual
---

<!--# files in: https://openneuro.org/datasets/ds004073/versions/1.0.0 -->

<!--# for previous attempt at intro see flip method script-->

<!-- #I'd like to submit this to either Neurobiology of Language, or Open Research Europe, which is like Wellcome Open Research, but for work funded by ERC -->

```{r packages,echo=F,warning=F}
require(here)
require(tidyverse)

```

## Introduction

It has been established for many years that language processing depends on specialised areas in the left side of the brain in most people. Initial evidence came from observations of aphasia after brain lesions; as early as the mid 19th century it was noted that aphasia was strongly associated with left-sided damage [@berker1986]. Neurosurgeons subsequently developed the Wada test [@wada1960] in which each hemisphere was successively anaesthetised to determine which was dominant for language, again revealing the bias to left-sided language processing in most people. With the advent of modern brain imaging methods, it became possible to observe correlates of brain activation associated with different cognitive tasks, confirming the overwhelming population bias to left hemisphere processing for language generation. There is, however, a significant minority of people who depart from the population trend, with atypical lateralisation: this may take the form of reversal of the usual left-sided bias for language - right-hemisphere language, or an overall lack of bias - bilateral language.

Atypical lateralisation is of considerable theoretical interest to neuroscientists interested in the evolutionary origins and functional significance of laterality. In addition, it is relevant for understanding how individuals recover from unilateral brain injury and for planning epilepsy surgery. We need reliable and convenient methods for measuring functional lateralisation in individuals to further research in this area.

Functional transcranial Doppler ultrasound (fTCD) is an inexpensive and portable method for measuring lateralisation by comparing blood flow velocity in the left and right middle cerebral arteries (MCAs) during an activation task, relative to a resting baseline period. It is relatively insensitive to movement artefacts, and can be used with children aged 4 years and over [@bishop2014]. In a recent study, @parker2022 compared lateralisation indices (LIs) for six different language tasks in left- and right-handers. This study found that left-lateralisation characterised tasks involving language generation, but not those involving comprehension, and that lateralisation was generally weaker in left-handers. Split-half reliabilities were generally reasonable for all tasks (.7 or more). FTCD has excellent temporal resolution but its spatial resolution is limited to distinguishing left from right, as it simply measures blood flow in the MCAs. If we find a lack of lateralisation on a task, we cannot know whether the two hemispheres contribute equally, or whether there is left-biased activation in some regions, and right-biased activation in others. To answer questions about localisation, we need to turn to a different method, functional magnetic resonance imaging (fMRI). FMRI has complementary advantages and disadvantages to fTCD: it has very poor temporal resolution but good spatial resolution, and can measure changes in blood oxygenation in voxels as small as 1 mm^3^. By comparing LIs obtained with fTCD and fMRI on comparable tasks, we can gain some insights into the sensitivity of fTCD to regional changes in blood flow. However, comparison is complicated by measurement issues.

A recent study by @vingerhoets2023 used the Delphi approach [@hasson2000] to explore expert opinion on measurement of lateralisation using a range of techniques, including fTCD and fMRI. It concluded that there was still no agreement about the optimal way to measure lateralisation, and the key concept of bilateral language was ill-defined.

With fTCD, signals from left and right sides are normalised by dividing by the mean of that side, and each trial is baseline corrected by subtracting the mean value from a rest period prior to stimulation. When fTCD was first developed as a tool for investigating laterality, the LI was obtained by identifying a temporal window, or Period of Interest (POI), and taking the mean value in an interval defined as +/- 2 s around the absolute peak difference between left and right signals in the POI [@deppe1997]. This method had the disadvantage that it could give a biased LI estimate in individuals who had little difference between the two sides: if the peak difference changed from left to right in the course of the POI, then the larger peak would be used. This could create a spurious bimodality in the distribution of LIs in a sample. As an alternative, @woodhead2020 proposed using a simple subtraction method whereby the mean signal in the right MCA was subtracted from that on the left. The two methods were highly correlated, but the latter method gave a normal distribution of LIs in a sample. More recently, @thompson2022 proposed a method more analogous to that used in fMRI, where Generalised Models were used to estimate the interaction of side (left vs right) with time interval (POI vs non-POI) on the signal over a series of trials. This gave LIs that agreed well with the simpler subtraction method, but with a smaller error of measurement. For the current paper, we use the Generalised Additive Model described by @thompson2022 to estimate LIs from fTCD data. This gives a estimate of LI corresponding to a percentage difference in blood flow between left and right that is specific to the POI.

```{r demoDoppler,echo=F}
demodat <- read.csv(here('_optimal_writeup','demoDop_RH_WG.csv'))
w<-which(demodat$Condition=='L-R')
demodat$Condition[w] <- '(L-R)+100'
demodat$Channel<- demodat$Condition #just to have a more sensible name

basestart=-5 # baseline start
baseend=2 # baseline end
poistart=6 # period of interest start
poiend=17 # period of interest end

p <- ggplot(data=demodat, aes(x=Time, y=Velocity, group=Channel)) +
  geom_line(aes(color=Channel))+
  scale_color_manual(values=c("black", "blue", "red"))+
 xlim(-5,25)+
    scale_x_continuous(breaks = seq(-5, 25, by=5),name = "Time (s)")+
    geom_hline(yintercept = 100, linetype="solid", alpha = 0.8) +
    geom_vline(xintercept = 0, linetype="solid", alpha = 0.8) +
    annotate(geom="label", x=(basestart+baseend)/2, y=95, label="Baseline",hjust=0.5,size=3,fill='black',colour='white')+
    annotate(geom="label", x=(poistart+poiend)/2, y=95, label="Period of Interest",hjust=0.5,size=3,fill='black',colour='white')+
    geom_vline(xintercept = basestart, linetype = "dotted", alpha = 1) + # Start of Baseline
    geom_vline(xintercept = baseend, linetype = "dotted", alpha = 1) + # End of Baseline
    geom_vline(xintercept = poistart, linetype = "dotted", alpha = 1) + # Start of POI
    geom_vline(xintercept = poiend, linetype = "dotted", alpha = 1)+
  # End of POI
    ylab("Blood Flow Velocity") 

ggsave(here('_optimal_writeup','images','Doppler_demo.eps'),plot=p,width=5.5,height=3)

```

The optimal method for estimating laterality has been much debated in the field of fMRI [@bradshaw2017]. A computed laterality index (LI) is expected to depend on the task, and the region-of-interest (ROI), but it will also vary depending on the analytic approach. The starting point is a t-map derived in the usual way from the General Linear Model, which is used to contrast the condition of interest with a comparison condition, which may be either rest or another condition that differs on key task demands. The next step is to identify voxels from the t-map within the ROI that are above some activation threshold, thr, and compute the LI by the standard formula (L+R)/(L-R) where L and R are either the number of voxels, or the mean activation of voxels on L and R sides. In practice, it makes little difference whether number or mean activation is used in the formula. However, the choice of threshold, thr, can make a substantial difference to the LI. Various attempts have been made to tackle this aspect, and the bootstrapping method developed by @wilke2006 and @wilke2007 and implemented in the LI Toolbox has become widely accepted as a standard [@bradshaw2017], [@vingerhoets2023]. In this method, LIs are computed from numerous subsamples of data for a range of thresholds, ranging from zero to a maximum value determined by the maximum observed activation. A mean LI is then computed from all the estimated LI values, weighted by the size of the threshold, so giving more weight to LIs based on stronger activations. Although this bootstrap method is described as 'threshold free', it does exclude voxels with negative t-scores.

[@thompson2022] compared estimates of LI from different analytic methods for 31 participants studied by @bruckert2016, who had completed a Word Generation task with both fTCD and fMRI. The bootstrapped LI was computed after applying a mask combining frontal, temporal and parietal lobes, as an approximation of the MCA territory. For the standard bootstrapped fMRI LI, the correlation with fTCD LI was .669, rising to .712 when the denonimator of the LI formula was removed, and LI computed just as the difference between two sides (L-R). This latter approach was explored to give an unbounded measure of LI, similar to that obtained with fTCD. (The standard LI formula is bounded by -1 and +1, giving a skewed distribution).

The main focus of the @thompson2002 study was on developing the GAM approach to analysing fTCD data. Here we turn to consider in more detail how fTCD LI related to fMRI LI, using the same dataset from @bruckert2016. We consider two different tasks, Word Generation and Semantic Matching, and four additional ROIs, frontal, temporal, parietal and cerebellar. We contrast here the bootstrap LI for fMRI with an alternative approach to fMRI laterality analysis, the subtraction method <!--# I think it might be better not to call it flip since that seems to be used in different ways by different people -->, which was designed to be more comparable to the fTCD approach. This is described in more detail below, but essentially is a threshold-free method that involves subtracting R from L voxel t-map activations from homologous regions in a sparse sample of voxels from the ROI. This process is repeated to give a distribution of LI values from which a mean and 95% confidence interval can be obtained.

This is an exploratory study where the principal focus is on discovering which fMRI measurement method and ROI agrees best with fTCD LI. In addition, we consider the confidence interval around the LI estimates for different methods.

## Methods

### **Design**

A within-subjects design was used where participants were tested in two sessions: the first using fTCD, and the second using fMRI. On average, the interval between the two sessions was 11.8 days (range: 1 to 31 days).

In both sessions participants performed two tasks: a speech production task (word generation) and a semantic matching task based on the Pyramids and Palm Trees test [@howard1992]. The tasks were designed to be as similar as possible in the two modalities (fTCD and fMRI), but some minor differences were required as noted below. Hence, the main within-subject independent variables were method (fTCD versus fMRI) and task (word generation versus semantic decision) and the dependent variable was laterality index (LI). For the semantic matching task, we included a comparison ("baseline") line judgement task, and we present LIs both from semantic matching vs rest, and semantic matching vs line judgement. <!--# not sure if necessary - currently just sem vs control shown -->

For comparison of different methods of fMRI analysis, we also considered data from an auditory naming task that was not used with fTCD. The data were acquired as part of a larger study involving the two testing sessions reported here and a later follow-up session which involved administration of a neuropsychological battery and a visual half-field task; for details see @bruckert2016.

### **Participants**

Participants were recruited from a sample of 231 individuals who were initially screened with fTCD in the first testing session. These participants were recruited from the Oxford Psychology Research Participant Recruitment Scheme (<https://opr.sona-systems.com>). All participants gave written, informed consent, and all procedures were approved by the Central University Research Ethics Committee of the University of Oxford (MSD-IDREC-C1-20014-003).

In order to obtain a sample with cases of both typical and atypical lateralisation, all 21 participants who showed right lateralised or bilateral activation during word generation in fTCD were invited to return for the second session with fMRI. This classification was based on whether or not the confidence interval (CI) for the LI index on Word Generation crossed zero, where the CI was derived from the standard error of the LIs obtained on individual trials. 16 of these participants agreed to take part and fulfilled all MRI safety criteria. A sample of 16 participants with left lateralisation for word generation in fTCD, matched for age, gender and handedness, were also invited to return for the second session. The final sample that participated in both sessions comprised 32 participants (14 women, 18 men; 20 right handed, 12 left handed; mean age = 24.9 years, SD = 5.1 years). Due to time constraints, one participant completed only the word generation task in the fTCD session, so the final sample size was N=31 for analyses including fTCD semantic matching data.

### **Functional Transcranial Doppler Ultrasound (fTCD)**

#### ***Procedure***

FTCD was acquired during the first session. Participants were trained to perform the two tasks and completed some practice trials; then the fTCD headset and probes were fitted and a stable signal was found. The fTCD signal was then recorded, first for the word generation task, then for the semantic matching task, with a break in between.

The timings for the two tasks are shown in Figure 1. Both tasks had a trial structure that started with a 'Clear Mind' instruction on screen (5 seconds), followed by the task for 20 seconds, and ending with 25 seconds of a rest where the word 'Relax' was presented on screen. Participants were instructed to stay still and think of as little as possible during the 'Relax' period. The onset of the 'Clear Mind' cue was taken as the start of the trial (peri-stimulus time = 0s).

Data and materials can be found on Open Science Framework: <https://osf.io/tkpm2/>. Scripts and outputs for fTCD analyses can be found at <https://osf.io/gw4en/>.

### ***Word Generation***

In this task (also known as verbal or phonemic fluency) a letter was presented in the centre of a screen and the participant was required to covertly (silently) generate as many words as possible starting with that letter. There were 23 trials, each with a different letter (excluding Q, X and Z) presented in a randomised order. After the 'Clear Mind' cue, the letter was presented on screen for 2.5 seconds, followed by a blank screen for 12.5 seconds. Participants were required to covertly generate words beginning with the letter during this period. A 'Say Words' cue was then presented for 5 seconds, during which participants were required to overtly report the words they had generated. The time course is illustrated in Figure 1.

![Figure 1. Time-course of trials in expressive (word generation) and receptive (semantic matching) tasks. <!--# need to redo name in figure decision->match -->](images/Fig1_ftcd_timings.png){alt="Figure 1. Time-course of trials in expressive (word generation) and receptive (semantic decision) tasks."}

### ***Semantic Matching***

<!--# to avoid confusion with COLA data, I have changed the name-->

In the semantic matching task (based on the picture version of the Pyramids and Palm Trees test; @howard1992) a triad of line drawings was presented, one at the top of the screen and two below. The participant was required to decide which of the two pictures below was the closest semantic match to the one at the top and respond by button press. There were 15 trials. For each trial, after the 'Clear Mind' cue, the participant was presented with 8 consecutive picture triads, each lasting 2.5 seconds. Participants reported their decision by keyboard button press using their left or right index fingers. The location of the target picture was counterbalanced so that an equal number of left or right button presses was required. The time course of trials is shown in Figure 1.

### ***Data Acquisition***

The fTCD data were recorded from the left and right middle cerebral arteries (MCAs) simultaneously using two ultrasound monitoring probes held in place using an elastic headset. The signal was recorded using a Doppler-Box^TM^X receiver and processed using QL software (v3.2) on a laptop PC. All equipment (the probes, headset, receiver box and software) were from Compumedics DWL®. The experimental tasks were presented on a PC monitor using Presentation Software (Neurobehavioural Systems) which sent marker pulses to the Doppler-Box^TM^X system to denote the onset of each trial.

### ***Data Analysis***

The fTCD probes recorded the cerebral blood flow volume (CBFV) from left and right middle cerebral arteries (MCAs) while participants performed the tasks. The CBFV data were analysed using custom scripts in R Studio (RStudio Team, 2015). The analysis followed the process described by @woodhead2019. In brief, the this included downsampling from 100 Hz to 25 Hz; epoching from -12 s to 30 s peri-stimulus time; artefact rejection (both manual for gross artefacts and automatic for signal intensities outside of the 0.0001-0.9999 quantiles); signal normalisation; heart cycle integration; baseline correction using ten seconds of rest immediately preceding each trial as a baseline level; a final artefact detection stage where trials containing signal below 60% or above 100% of the mean normalised CBFV were rejected; and averaging of all trials (excluding rejected trials) for each task.

### ***LI Calculation***

For LI calculation we departed from the method used by Bruckert (2016) and adopted the Generalised Additive Model approach described by @thompson2022, which is more comparable to the Generalised Linear Model method used with fMRI. Note that, as shown by Thompson et al (2022), the individual LI values obtained with this method are closely comparable to those obtained by subtracting averaged left and right cerebral blood flow velocities; however, the LI estimates have smaller standard errors than those from more traditional methods.

### ***Data Quality***

The data was checked for adequate quality in two ways. Firstly, if any participant had more than 20% of trials rejected (i.e. more than 5 trials for word generation or more than 3 trials for semantic matching), the participant would be excluded from the analysis. Secondly, the trial-by-trial variability was assessed using the standard error of LI values for each trial. The fTCD data was previously analysed as part of a larger sample of 156 participants (Bruckert et al, 2019). Outlier standard error values were identified in that dataset, and excluded from the analysis.

No participants were excluded from the current analysis on the basis of these two quality checks.

## 

### **Functional Magnetic Resonance Imaging (fMRI)**

#### ***Procedure***

FMRI was acquired in the second session. Participants were first briefed on the imaging protocol and practiced the tasks outside of the scanner. They were then positioned in the scanner and a structural brain image was acquired. Three tasks were then performed in separate runs, each lasting six minutes. As well as word generation and semantic matching, an auditory naming task was also used. The order of task presentation was counterbalanced between participants.

#### ***Word Generation***

This task was performed similarly to in fTCD, but owing to fMRI's greater susceptibility to motion artefacts there was no overt word reporting phase. A block design was used, where the task was performed for 15 seconds followed by 15 seconds of rest (with a fixation cross). There were 12 blocks, each with a different letter presented on the screen throughout the duration of the block. Participants were required to covertly think of as many words as they could starting with that letter. The 12 letters (A, B, E, G, J, K, M, N, O, S, U, V) were presented in a randomised order.

#### ***Semantic Matching***

The picture triad stimuli were presented similarly to in fTCD. Each fMRI block comprised eight picture triads, each with a duration of 2.5 seconds (20 seconds in total). The participants were required to respond by button press using their left and right thumbs on an MRI-compatible button box.

Unlike the word generation task, a comparison task (active perceptual baseline) was also acquired during the semantic matching fMRI run. This used a line drawing matching task, where triads of abstract line drawings were presented in the same format as for the semantic matching task. Participants were required to detect which of the two drawings at the bottom was a perceptual match to the target drawing at the top and respond by button press.

The run comprised six blocks of semantic matching, six blocks of line decision and six rest blocks (where participants saw a fixation cross for 20 s), presented in a pseudo-randomised order where no condition was shown twice in a row.

#### ***Auditory Naming***

The auditory naming paradigm (AN) was based on the Auditory Responsive Naming task [@bookheimer1998] and identical to the one used by @badcock2012a, who adapted this task for the use in FMRI. Participants heard short definitions of a high frequency nouns through MRI compatible in-ear headphones (model S14, Sensimetrics), and were required to silently generate the described word (e.g. the participant heard 'shines in the sky' and thinks of 'sun'). Because this task used an auditory presentation, which creates substantial activation in auditory cortex, a reversed speech condition (same recordings played backwards) was included, so the effect of auditory stimulation could be controlled for.

***Data Acquisition***

Scanning was performed in a Siemens 3T Trio scanner with a 32-channel head coil. The task stimuli were presented using Presentation Software (Neurobehavioural Systems) with stimulus onset synchronised with the scanner. The stimuli were projected via a mirror mounted on the head coil.

A high resolution T1-weighted MPRAGE was acquired for image registration (TR=2040 ms, TE=4.7 ms, flip angle=8°, 192 transverse slices, 1 mm isotropic voxels). Echo-planar images were acquired to measure change in blood oxygen levels during the behavioural tasks (TR=3s, TE=30 ms, flip angle=90°, 48 axial slices, slice thickness=3 mm, in-plane resolution=3 x 3 mm). \<query in Zoe original 'field maps? \>

#### ***Data Analysis***

Data analysis was conducted using FEAT (the fMRI Expert Analysis Tool) in FSL (FMRIB Software Library, <http://www.fmrib.ox.ac.uk/fsl>). The preprocessing stages included head motion correction through realignment to the middle volume of the EPI dataset; skull stripping using FSL's Brain Extraction Tool (BET; [@smith2002]; spatial smoothing using a 6 mm full-width-half-maximum Gaussian kernel; high-pass temporal filtering at 90 seconds; and unwarping using fieldmaps in FSL's Phase Region Expanding Labeller for Unwrapping Discrete Estimates tool (PRELUDE) and FMRIB's Utility for Geometrically Unwarping EPI (FUGUE; @jenkinson2003).

The preprocessed data were entered into first-level (subject-specific) general linear models (GLMs). The word generation and semantic matching runs were analysed separately. The explanatory variables (EVs) in the GLM were: the timecourse of the active tasks (word generation, or semantic matching and line decision) convolved with a double-gamma function; the temporal derivatives of the timecourse EV; and six motion correction parameters as covariates of no interest. For word generation, the contrast of interest was word generation versus the implicit (resting) baseline. For semantic matching, two contrasts were extracted: semantic matching versus rest, and semantic matching versus line decision. For auditory naming, one contrast was used, i.e., auditory naming vs reversed speech.

<!--# need to have more detail here on FLIRT - can put processing scripts on OSF-->

#### ***LI Calculation***

The following methods for calculating LI~fMRI~ were compared:

1.  Conventional threshold-independent LI

    The t-statistic maps <!--# I have redone all analyses with t-maps --> were used to calculate LI values using the conventional formula LI = (L-R) / (L+R). The bootstrapping method in the LI Toolbox [@wilke2006; @wilke2007] was used to give a threshold-independent LI for each task and ROI. This method (described in @bradshaw2017; @wilke2007 ) takes an iterative approach, first by varying the t-threshold applied to the ROI data in 20 equally-spaced thresholds from 0 to the maximum t-value in the image. At each threshold, the bootstrapping procedure takes 100 different re-samples of the t-statistics within the thresholded ROI, where the size of the re-sample is 25% of all voxels by default. An LI value is calculated for every combination of these re-samples (100\*100=10,000 LI values) at each threshold level (20 thresholds x 10,000=200,000 LI values). These are plotted in a histogram and weighted by t-threshold. A trimmed mean of all of the weighted LI values is taken, to give a final LI value that is threshold-independent.

    The LI Toolbox software does not provide a confidence interval for the weighted mean. We computed one by creating a new histogram of LIs, taking a proportion of LIs, weighted by threshold, as illustrated in Table x. The mean of these values agrees with the weighted mean computed by the LI toolbox. The 5th and 95th centiles were determined empirically for each histogram to give a 95% confidence interval. <!--# I've just realised that this will actually give a 90% CI?  Need to check. It is already so big I don't want to make it any bigger! -->

2.  Subtraction method

    We explored a version of the flip method, which was used by @watkins2001 to assess structural asymmetries in human MRI. In this method, rather than assessing how many voxels are activated in left and right hemispheres, the right-brain image is flipped and then subtracted from the left-brain image.

    The flip method has occasionally been applied to functional MRI (@baciu2005; @cousin2007) but there is little consensus on how to derive an individual LI from this approach. We term our method the Subtraction Method to avoid confusion with other approaches. To minimise spatial dependencies between voxels, we took 1000 samples, each containing a random 5% of voxels in the region, and then computed the difference score at each voxel. The mean, 5th and 95th percentiles were taken from the 1000 estimates to give a confidence interval around the difference score. Note that this method is threshold-independent, with all t-map values being included, regardless of whether positive or negative.

    To make it easier to visualise the subtraction method data on the same scale as the LI toolbox data, the differences were divided by the absolute maximum difference in the sample, 2.7, so that the scale maximum was 1.0. Note, however, that these values are not conventional laterality indices, as they are simple differences, rather than proportions. We refer to these as scaled subtraction LI.

    In line with recommendations from Vingerhoets et al (2023), we report the mean activation scores for voxels on the left and right side before presenting the mean LI scores.

#### ***Regions of Interest***

Initial comparisons of methods were done using a combined mask of the frontal, temporal and parietal lobes as an approximation of the MCA territory. This mask was selected for comparability to the fTCD method, where the LI is based on comparisons of blood flow in left and right MCAs.

The left and right mean activations and LI values were then calculated separately for the following ROIs, frontal, temporal, parietal, cerebellar, as defined by masks in the LI Toolbox, which are based on a population-based atlas (Hammers et al., 2003).

In all analyses a region 5 mm either side of the midline was excluded from consideration, again using a template provided in the LI Toolbox,

## **Data Analysis**

Comparison of LI estimates from fCTD with bootstrap and subtraction methods.

The first set of analyses involved comparing the LIs from fTCD with those from fMRI for each combination of task (Word Generation and Semantic Matching) x LI method (Bootstrap and Subtraction) for the MCA mask.

A second set of analyses was conducted to look at the agreement between LI estimates from fMRI obtained using different ROIs and those from fTCD for the two tasks.

The similarity between LI~fMRI~ and LI~fTCD~ was assessed using scattergraphs and bivariate correlations. As we anticipate that the LI values may not fit a normal distribution, we will use Spearman's rank correlations instead of Pearson's correlations. It should be noted that there is no well-established method for testing the significance of a difference between non-parametric correlations (Howell, 2010; Wilcox & Tian, 2008); however, the analyses presented here are exploratory, with the aim of better understanding the similarities and differences between laterality measured in fMRI and fTCD -- therefore, statistical significance is not the key concern. Instead, bootstrapping will be used to calculate the 95% confidence intervals around the Spearman's correlations.

## Results

### 1. Correspondence of LI in the MCA from fTCD and fMRI, according to task and fMRI-LI method 

```{r packages, echo=F, warnings=F}
require(here)
require(tidyverse)
require(RVAideMemoire) #for spearman ci
```

```{r plotMCA}
bigdf<-read.csv(here('Data_processed','bigdf.csv'))

```

\<!\--# These functions are from COLA_RR_Results.Rmd

```{r numformat,echo=F}
numformat=function(mynum,ndecimals){
  newnum <- format(round(mynum,ndecimals),nsmall=ndecimals)
  return(newnum)
}
```

```{r corformat,echo=F}

corformat=function(mynum,ndecimals){
  newnum <- format(round(mynum,ndecimals),nsmall=ndecimals)
  neg<-''
  if(mynum<0){
    neg<-'-'
    mynum<-substring(newnum,2)} #strip off minus sign - will put it back later
  newnum<-substring(newnum,2) #strip off initial zero
  newnum<-paste0(neg,newnum)
  
  return(newnum)
}

```

```{r pformat, echo=F}
#function to format p-values, without the 'p = ' bit
pformat2=function(myp){
  pout <- numformat(myp,3)
  if(myp<.001){pout ='< .001'}
  return(pout)
}

```

```{r makescatterplots}
#We use same chunk to make scatterplot for MCA as well as for the ROIs
#method options are "Doppler","flip","toolbox" - now with flipLI which is LI from flip data
mask <- c("mca" , "frontal" ,"temporal" ,"parietal" , "cerebellar")
mymethod <- c('Doppler','flip','toolbox','flipLI')
tlist <- c('WG1','PP1') #for now we just use first two methods
longlist <- c('Word Generation', 'Semantic Match','Sem Match - Baseline')#
shortlist<-c('Word G','Sem Match','Sem Match - baseline')
allplot <- list() #clear list
mycount <-0
for (t in 1:length(tlist)){ #new plot started with new task
mytask <- tlist[t]
longtask <- longlist[t]

meth1 <- 1
for (meth2 in seq(3,2,by=-1)){ #methods 2 and 3 will be compared side by side
method1 <- mymethod[meth1]
method2 <- mymethod[meth2]
methodlabel <- c('fTCD GAM - rescaled','fMRI: Subtracted - rescaled','fMRI: LI toolbox')

mytaskx <- mytask
if(mytaskx=='PP5' && meth1 ==1){mytaskx <- 'PP1'}

for (thismask in 1:5){
mymask <- mask[thismask]
mytitle <- paste0(str_to_title(mymask),": ",longtask)
if(thismask==1){
  mytitle <- paste0(str_to_upper(mymask),": ",longtask)
}

mycount <- mycount+1 #used to count the plots

xfile <- filter(bigdf,method==method1 & task==mytaskx & mask=='mca') #doppler only has mca equiv and only has pp1 and wg1
yfile <-  filter(bigdf,method==method2 & task==mytask & mask==mymask)



#Check that rows are equivalent
s<-c(xfile$id,yfile$id)
myn<-table(s)
my2 <- names(which(myn==2))
xfile<-xfile[xfile$id %in% my2,]
yfile <- yfile[yfile$id %in% my2,]
w<-which(names(xfile)=='mean')
names(xfile)[w:(w+2)]<-c('x','xmin','xmax')
names(yfile)[w:(w+2)]<-c('y','ymin','ymax')
pbilat <- round(100*length(which(yfile$nulatgroup=='B'))/nrow(yfile),0) #% bilat
forplot<-cbind(xfile,yfile[,w:(w+2)])

corspear <-spearman.ci(forplot$x,forplot$y, nrep = 1000, conf.level = 0.95)
rs <- round(corspear$estimate,3)
ci1<-round(corspear$conf.int[1],3)
ci2<-round(corspear$conf.int[2],3)
cortext <- paste0('r[s] = ',rs,'\n[',ci1,', ', ci2,']')

#add some text re % bilateral


myplot <- ggplot(data = forplot,aes(x = x,y = y)) + 
  geom_point(aes(col=Doplat),size=.5)+
  geom_errorbar(aes(ymin = ymin,ymax = ymax,col=Doplat)) + 
  geom_errorbarh(aes(xmin = xmin,xmax = xmax,col=Doplat))+
  geom_hline(yintercept = 0, linetype="solid",col='grey') + 
  geom_vline(xintercept = 0, linetype= "solid", col='grey')  + 
  xlim(-1,1)+
  ylim(-1,1)+
  ylab(methodlabel[meth2])+
  annotate("text",x = -.5, y = .85, label = cortext,col='black',size=3)+
  annotate("text",x = 0, y = -.8, label = paste0(pbilat,'% bilateral on fMRI'),col='black',size=3)+
    scale_color_manual(values=c( "gray40","blue","red"))+
  guides(col=guide_legend(title='Laterality category: fTCD'))
if(thismask==1){ #mca
  if(meth2==3){
    myplot <- myplot +
      ggtitle(longlist[t])
  }
  if (meth2<3){
    myplot <- myplot +
      ggtitle(" ") #need to specify blank title or plots get misaligned
  }
  if(t==2){ #only want label for x axis on bottom plot
    myplot <- myplot +
      xlab(methodlabel[meth1])
  }
  if(t==1){
    myplot <- myplot +
      xlab(" ")
  }
}

if(thismask>1){
  
  if(meth2==3){ #this is bootstrap LI: will be the left-hand plot
    temptitle = paste(longlist[t],"\n",mask[thismask])
    if(thismask>2){
       temptitle = mask[thismask] #only put task on top one
        }
  myplot <- myplot +
    ggtitle(temptitle)
   }
if (meth2<3){
  myplot <- myplot +
    ggtitle(" ") #need to specify blank title or plots get misaligned
}
if(thismask==5){ #only want label for x axis on bottom plot
  myplot <- myplot +
    xlab(methodlabel[meth1])
}
if(thismask<5){
  myplot <- myplot +
    xlab(" ")
}
}

myplot <- myplot + theme(axis.title.x = element_text( size=10))+
  theme(axis.title.y = element_text(size=10))


allplot[[mycount]] = myplot
}
}
}
  
#plots for paper
myplot1 <- ggarrange(allplot[[1]],allplot[[6]],allplot[[11]],allplot[[16]],nrow=2,ncol=2,common.legend=TRUE)
savename<-paste0('Doppler_fmri2meth_MCA_2task','.eps')

ggsave(here('Plots',savename),myplot1,width=6,height=6,dpi=300)

#additional plots for powerpoint
myplot2 <- ggarrange(allplot[[2]],allplot[[7]],allplot[[3]],allplot[[8]],nrow=2,ncol=2,common.legend=TRUE)
savename<-paste0('Doppler_fmri2meth_fronttemp_',mytask,'.eps')

ggsave(here('Plots',savename),myplot2,width=6,height=6,dpi=300)

myplot3 <- ggarrange(allplot[[4]],allplot[[9]],allplot[[5]],allplot[[10]],nrow=2,ncol=2,common.legend=TRUE)
savename<-paste0('Doppler_fmri2meth_parcereb_',mytask,'.eps')

ggsave(here('Plots',savename),myplot3,width=6,height=6,dpi=300)

myplot4 <- ggarrange(allplot[[2]],allplot[[7]],allplot[[3]],allplot[[8]],allplot[[4]],allplot[[9]],allplot[[5]],allplot[[10]],nrow=4,ncol=2,common.legend=TRUE)
savename<-paste0('Doppler_fmri2meth_4ROI_WG1.eps')

ggsave(here('Plots',savename),myplot4,width=5,height=10,dpi=300)


myplot5 <- ggarrange(allplot[[12]],allplot[[17]],allplot[[13]],allplot[[18]],allplot[[14]],allplot[[19]],allplot[[15]],allplot[[20]],nrow=4,ncol=2,common.legend=TRUE)
savename<-paste0('Doppler_fmri2meth_4ROI_PP1.eps')

ggsave(here('Plots',savename),myplot5,width=5,height=10,dpi=300)





```

![Scatterplots of relationship between fTCD and two methods of fMRI laterality](images/Doppler_fmri2meth_MCA_2task.eps)

Figure x shows the relationship between fTCD laterality (x-axis) and fMRI laterality (y-axis) for the original LI toolbox bootstrap method in the left panels and the new subtraction method in the right panels. The upper panels show results for Word Generation, and the lower panels for Semantic Matching. Points are colour-coded according to categorical laterality classification on fTCD for that task: grey points are those where the 95% confidence interval crosses zero, and are hence coded bilateral. Points in red are right-lateralised, and those in blue are left-lateralised. Note that the high proportion of bilateral/right-lateralised cases reflects the fact that the sample was selected to include a high proportion of atypically lateralised individuals. The plot also shows the Spearman correlation between fTCD and fMRI laterality, with the 95% confidence interval, obtained from bootstrap method in package RVAidememoire [@herve2021]. The percentage of individuals identified as having bilateral language on fMRI is also shown, again using the criterion of whether the 95% confidence interval of the estimate crosses zero.

Two points are immediately evident from the plots. First, with few exceptions, fMRI and fTCD categorisations agree fairly well, i.e., those categorised as right-lateralised on fTCD tend to have LI values below zero on fMRI, and those categorised as left-lateralised on fTCD tend to have LI values above zero on fMRI. Second, the 95% confidence intervals are considerably larger for the bootstrapped LI toolbox estimates than for the subtraction method: this has the consequence that a far higher proportion of toolbox estimates categorise the individual as having bilateral language.

We will discuss the implications of these results below, but first we turn to look at agreement for the four ROIs outlined above. Before plotting the results for the laterality indices, we look at the mean voxel activations on left and right for each region.

### 2. Left vs right activations on fMRI by task and region

```{r LRplots}
LRplot <- 1
if(LRplot==1){
#column with 'diff'
masktitle <- c('MCA','Frontal','Temporal','Parietal','Cerebellar')
tasktitle <- c('Word Generation','Semantic vs rest','Line vs rest','Semantic vs Line','Auditory Naming')
method1 <- 'flip' #the mean voxel activations are saved with the flip method
mycount <-0
allplot <- list()
for (thismask in 2:5){
mymask <- mask[thismask]


for (t in c(1,2)){ #WG1, PP1, 
mycount <- mycount+1
mytask <- task[t]
forplot <- filter(bigdf,method==method1 & task==mytask & mask==mymask)
w<-which(is.na(forplot$Doplat)) #find and remove rows with no Doppler lat
forplot <- forplot[-w,]
names(forplot)[2:3]<-c('Left','Right')


#correlcoef <- round(cor.test (forplot$Left, forplot$Right, method = "spearman",  exact = FALSE)$estimate,3) #not used
#censor values at 3
mycensor <- 3
forplot$Left[forplot$Left< (-mycensor)]<- (-mycensor)
forplot$Right[forplot$Right< (-mycensor)]<- (-mycensor)
 forplot$Left[forplot$Left>mycensor]<- mycensor
 forplot$Right[forplot$Right>mycensor]<- mycensor
myplot <- ggplot(data = forplot,aes(x = Right,y = Left)) + 
  geom_point(aes(col=Doplat),size=1.5)+
  geom_hline(yintercept = 0, linetype="solid",col='grey') + 
  geom_vline(xintercept = 0, linetype= "solid", col='grey')  + 
  geom_abline(intercept=0,slope=1,linetype= "dotted", col='black')+
  geom_hline(yintercept = mean(forplot$Left[forplot$Doplat=='L']),col='blue',linetype= "dashed")+
  geom_vline(xintercept = mean(forplot$Right[forplot$Doplat=='L']),col='blue',linetype= "dashed")+
  xlab("Activation R")+
  ylab("Activation L")+
   xlim(-mycensor,mycensor)+
   ylim(-mycensor,mycensor)+
  ggtitle(paste0(masktitle[thismask],":\n",tasktitle[t]))+
  scale_color_manual(values=c( "gray40","blue","red"))+
  guides(col=guide_legend(title='Laterality category: fTCD'))


 
allplot[[mycount]] = myplot
}
}
myallplot <- ggarrange(allplot[[1]],allplot[[2]],allplot[[3]],allplot[[4]],allplot[[5]],allplot[[6]],allplot[[7]],allplot[[8]],ncol=2,nrow=4,common.legend=TRUE)
savename<-paste0('LR_3tasks_4mask.eps')
ggsave(here('Plots',savename),myallplot,width=6,height=10,dpi=300)

}

```

![Mean L and R activations by task and ROI: dotted blue lines show mean for typically (L) lateralised individuals, as categorised on fTCD](images/LR_3tasks_4mask.eps)

Figure x shows the scatterplots with mean activations on left and right. The sloping dotted line is the point of equivalence for left and right: as expected, for the three ROIs contributing to the MCA, individuals who are categorised as left-lateralised tend to fall above this line, indicating more activation on left than right, and those who are right-lateralised tend to fall below the line. For the cerebellar mask, this pattern is reversed, with left-lateralised individuals showing greater activation on the right, and vice versa.

The plots also shows different patterns across ROIs in the levels of activation in the two hemispheres. We will focus here just on typically-lateralised individuals, whose means are indicated by the dotted blue lines. The sample size is too small for statistical analysis, but we can form some general impressions on visual inspection. Considering first Word generation: in the frontal lobe, typically-lateralised individuals tend to have positive activation in the left hemisphere, and zero activation in the right hemisphere. In the temporal lobe, there is a lesser degree of positive activation in the left hemisphere, coupled with an equivalent deactivation (i.e. mean values below zero) in the right hemsiphere. In the parietal lobe, there is no activation in the left hemisphere, but substantial deactivation in the right hemisphere. In the cerebellum, there is positive activation in both hemisphere, but greater in the right than the left.

The profile for Semantic matching is rather different, with a less striking difference between the two sides, and no sign of the parietal lobe right hemisphere deactivation seen with Word Generation.

### 3.  Correspondence of LI from fTCD and fMRI, according to task and region

Figures x and xx shows plots similar to those in Figure x, but broken down by ROI. Note that the fTCD, shown on the x-axis, cannot give information about ROI, as it is a simple measure of blood flow velocity in the left and right MCAs. The interest in these plots is to see whether fTCD shows any regional sensitivity in the laterality differences that are detected.

With the subtraction method, the fMRI shows good agreement with fTCD LI in frontal and parietal regions for both tasks, and also with the cerebellar region for the Word Generation task. The agreement is generally less good for the Toolbox LI.

### Discussion

The subtraction method for fMRI laterality estimates generally agrees well with fTCD laterality indices, whereas the Toolbox LI has weaker correlations. It is important to note that the fTCD LI cannot be regarded as a gold standard, as it does not have any sensitivity to localisation of activation. One possible explanation for the better agreement with subtraction LI is simply that the data processing is similar in the two methods, involving simple subtraction of measures of activation on the left and right.

There are, however, two other aspects of the data that suggest two other reasons why the Toolbox LI may give weaker agreement with fTCD LI: first, it ignores task-related deactivation, and second, it will be influenced by the range of thresholds that are used in its calculation.

#### Importance of task-related deactivation

The data on left and right hemisphere mean activations shown in Figure x suggests that language laterality may depend on deactivation as well as activation. Indeed, this is already suggested by scrutiny of the mean task related blood flow evident in the fTCD data (Figure x). On the Word Generation task, we first see an increase in blood flow to both hemispheres as the participant starts to perform the task, but then blood flow declines in both hemispheres, with the right hemisphere values dropping below the baseline level.

The ROI analyses shown in Figure x show that deactivation is region-dependent. The data from the parietal lobe is particularly striking: even for those with typical language lateralisation, we see average deactivation in both left and right hemispheres, with the deactivation being more marked on the right.

The mechanism underlying such phenomena is not understood, though we know that the Circle of Willis allows for compensatory changes in blood flow between posterior and anterior cerebral blood vessels, and between the two sides of the brain. It is possible that a task that makes increased metabolic demands in the left frontal lobe will lead to a corresponding decrease in blood flow in posterior regions, and in the right hemisphere relative to the left.

If, as seems to be the case, functional lateralisation for language is manifest in deactivation of some regions, then we will fail to detect this phenomenon by relying on a laterality index that ignores all voxels with negative t-values.

#### Impact of thresholds in LI Toolbox estimates

There is a striking difference in the confidence intervals associated with the Toolbox LIs and those estimated from the same data using the subtraction approach - so much so that we initially suspected a computational error may be implicated. However, the LI Toolbox estimates have very large standard errors precisely because they are based on a very wide range of thresholds. Figure x shows illustrative histograms that form part of the output of the LI Toolbox. These come from a single person and task. One can see that the LI estimates cover a very broad range, but the distribution is far from uniform: individual clusters of LIs in the histogram have highly peaked distributions: each of these corresponds to a different threshold at which the LI is estimated. There is little variation of estimates within a threshold, but substantial variation between thresholds. Furthermore, these estimates are based on different amounts of data - the more extreme the threshold, the fewer the datapoints it is based on. The Toolbox gives the user a wide range of options for computing the LI, ranging from a simple mean, a trimmed mean, and a weighted mean - all of these take the whole set of data represented in the histogram, but the weighted mean weights the values according to the threshold, so giving more importance to higher activations. This means, however, that the greatest weight is given to the least reliable LI estimates, and the estimates based on the zero threshold are discarded. In the example shown in Figure x, the weighted mean of .19 is substantially lower than the simple average, as it is heavily influenced by the LI becoming right-biased at high thresholds.

It is also worth noting that the range of thresholds used in the default settings of the LI toolbox is determined by the maximum t-value in the dataset. So a dataset with maximum value
